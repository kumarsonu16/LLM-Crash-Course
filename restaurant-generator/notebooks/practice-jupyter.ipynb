{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b8cb8b7-8936-41f0-9a83-8423aebf2316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-proj-N5DMjGCG2FQxb5FZNEteT3BlbkFJkqUbFmqOJx7Oc5SImmUm\n"
     ]
    }
   ],
   "source": [
    "from sceret_key import OPENAI_API_KEY\n",
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_API_KEY\n",
    "print(os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7091090e-ec88-4fe4-9668-2df87c87985d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\"IndiSpice Fusion Eatery\" \n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature=0.6) # temperature for defining risk and creativity\n",
    "name = llm(\"I want to open a restaurant for indian food. Suggest a fancy name for this\")\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "565f399a-4670-4d6e-a074-a732aec96e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a restaurant for Italian food. Could you suggest a fency name for this?'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a prompt so that we can pass any cuisine as a placeholder to your message as dynamically\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables =['cuisine'],\n",
    "    template = 'I want to open a restaurant for {cuisine} food. Could you suggest a fency name for this?' \n",
    ")\n",
    "prompt_template_name.format(cuisine=\"Italian\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3eba03f-22eb-4056-9482-2889ca713062",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\"La Cantina de Mexico\"'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "name_chain.run(\"Mexican\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "055cb2dd-763d-47e3-a51c-a743adacebd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Suggest some menu items for La Cantina de Mexico. Return it as a comma-separated list'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables =['restaurant_name'],\n",
    "    template = 'Suggest some menu items for {restaurant_name}. Return it as a comma-separated list' \n",
    ")\n",
    "prompt_template_items.format(restaurant_name=\"La Cantina de Mexico\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5de165e-ed25-48f8-9cfc-6e6ec81c6a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Prompt for both name and menu to call with Sequential chain as we have sequence for restaurant then the menu\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables =['cuisine'],\n",
    "    template = 'I want to open a restaurant for {cuisine} food. Could you suggest a fency name for this?' \n",
    ")\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name)\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables =['restaurant_name'],\n",
    "    template = 'Suggest some menu items for {restaurant_name}. Return it as a comma-separated list' \n",
    ")\n",
    "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce21e6b5-3ea3-4348-be1c-9fff239981e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'Indian', 'output': '\\n\\n1. Spicy Tandoori Chicken\\n2. Masala Dosa\\n3. Lamb Vindaloo\\n4. Vegetable Samosas\\n5. Butter Chicken\\n6. Palak Paneer\\n7. Chicken Tikka Masala\\n8. Aloo Gobi\\n9. Garlic Naan\\n10. Mango Lassi\\n\\n\"Spice Symphony\" menu items: Spicy Tandoori Chicken, Masala Dosa, Lamb Vindaloo, Vegetable Samosas, Butter Chicken, Palak Paneer, Chicken Tikka Masala, Aloo Gobi, Garlic Naan, Mango Lassi'}\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains = [name_chain, food_items_chain])\n",
    "response = chain.invoke(\"Indian\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2799139-fbfa-4f71-8206-9da7c53818ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create chains with output keys\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables =['cuisine'],\n",
    "    template = 'I want to open a restaurant for {cuisine} food. Could you suggest a fency name for this?' \n",
    ")\n",
    "name_chain = LLMChain(llm=llm, prompt=prompt_template_name, output_key=\"restaurant_name\")\n",
    "\n",
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables =['restaurant_name'],\n",
    "    template = 'Suggest some menu items for {restaurant_name}. Return it as a comma-separated list' \n",
    ")\n",
    "food_items_chain = LLMChain(llm=llm, prompt=prompt_template_items, output_key=\"menu_items\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2152c8e3-0b7e-4049-82e1-3ec8c48c61b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuisine': 'Arabic',\n",
       " 'restaurant_name': '\\n\\n\"Al-Khayma\" (meaning \"the tent\") or \"Sultana\\'s Table\"',\n",
       " 'menu_items': '\\n\\n\\n1. Mezze platter (hummus, baba ghanoush, tabbouleh, falafel)\\n2. Lamb kabobs with tzatziki sauce\\n3. Chicken shawarma wrap\\n4. Beef kofta with rice pilaf\\n5. Grilled vegetable skewers\\n6. Fattoush salad\\n7. Spinach and feta borek\\n8. Lentil soup\\n9. Baklava for dessert\\n10. Turkish coffee or mint tea to finish off the meal.'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import SequentialChain\n",
    "\n",
    "chain = SequentialChain(\n",
    "            chains = [name_chain, food_items_chain],\n",
    "            input_variables = ['cuisine'],\n",
    "            output_variables = ['restaurant_name', 'menu_items']\n",
    "        )\n",
    "\n",
    "chain({'cuisine': 'Arabic'})\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
