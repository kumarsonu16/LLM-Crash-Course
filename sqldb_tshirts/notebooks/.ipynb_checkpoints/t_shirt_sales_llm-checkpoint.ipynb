{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06cbb6f8-2243-4ab6-b80b-80f53ac80aba",
   "metadata": {},
   "source": [
    "#### GoogleGenerativeAI with LLM & API key setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "972dede0-5444-4efa-9a34-6cc4d06a534c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (0.2.16)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "langchain-community 0.2.16 requires langchain<0.3.0,>=0.2.16, but you have langchain 0.3.0 which is incompatible.\n",
      "langchain-community 0.2.16 requires langchain-core<0.3.0,>=0.2.38, but you have langchain-core 0.3.0 which is incompatible.\n",
      "langchain-experimental 0.0.65 requires langchain-core<0.3.0,>=0.2.38, but you have langchain-core 0.3.0 which is incompatible.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: langchain_google_genai in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (1.0.10)\n",
      "Collecting langchain_google_genai\n",
      "  Downloading langchain_google_genai-2.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (3.9.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (0.3.0)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (0.1.120)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (2.9.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: google-generativeai<0.8.0,>=0.7.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain_google_genai) (0.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.6 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.6.6)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.19.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.137.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (2.32.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.25.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.12.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.24.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (24.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.5)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.63.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.9)\n",
      "Requirement already satisfied: anyio in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain) (2.1)\n",
      "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (4.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.64.1)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.6->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (1.62.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (3.0.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai<0.8.0,>=0.7.0->langchain_google_genai) (0.4.8)\n",
      "Downloading langchain-0.3.0-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.0/1.0 MB 660.6 kB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.0/1.0 MB 660.6 kB/s eta 0:00:02\n",
      "   - -------------------------------------- 0.0/1.0 MB 281.8 kB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.1/1.0 MB 438.1 kB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 0.1/1.0 MB 504.4 kB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 0.1/1.0 MB 502.3 kB/s eta 0:00:02\n",
      "   -------- ------------------------------- 0.2/1.0 MB 655.6 kB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 0.3/1.0 MB 770.1 kB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.3/1.0 MB 781.9 kB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.4/1.0 MB 836.4 kB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.5/1.0 MB 921.6 kB/s eta 0:00:01\n",
      "   -------------------- ------------------- 0.5/1.0 MB 874.6 kB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 0.6/1.0 MB 915.2 kB/s eta 0:00:01\n",
      "   ------------------------- -------------- 0.6/1.0 MB 992.0 kB/s eta 0:00:01\n",
      "   -------------------------- ------------- 0.7/1.0 MB 953.9 kB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 0.7/1.0 MB 955.7 kB/s eta 0:00:01\n",
      "   --------------------------------- ------ 0.8/1.0 MB 1.0 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 0.8/1.0 MB 983.9 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 0.9/1.0 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  1.0/1.0 MB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.0/1.0 MB 1.1 MB/s eta 0:00:00\n",
      "Downloading langchain_google_genai-2.0.0-py3-none-any.whl (39 kB)\n",
      "Downloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: langchain-text-splitters, langchain, langchain_google_genai\n",
      "  Attempting uninstall: langchain-text-splitters\n",
      "    Found existing installation: langchain-text-splitters 0.2.1\n",
      "    Uninstalling langchain-text-splitters-0.2.1:\n",
      "      Successfully uninstalled langchain-text-splitters-0.2.1\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.2.16\n",
      "    Uninstalling langchain-0.2.16:\n",
      "      Successfully uninstalled langchain-0.2.16\n",
      "  Attempting uninstall: langchain_google_genai\n",
      "    Found existing installation: langchain-google-genai 1.0.10\n",
      "    Uninstalling langchain-google-genai-1.0.10:\n",
      "      Successfully uninstalled langchain-google-genai-1.0.10\n",
      "Successfully installed langchain-0.3.0 langchain-text-splitters-0.3.0 langchain_google_genai-2.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade langchain langchain_google_genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ac7c502-471d-4eeb-a8b0-228ee6014f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Ode to Dosa**\n",
      "\n",
      "Oh, crispy dosa, my savory delight,\n",
      "A culinary wonder, a morning's bright.\n",
      "Your batter, smooth and light, a perfect blend,\n",
      "Spread thin and wide, a canvas without end.\n",
      "\n",
      "Your golden hue, a beacon in the dawn,\n",
      "Your aroma wafts, a symphony withdrawn.\n",
      "With every bite, a burst of flavors bold,\n",
      "A tapestry of spices, a story yet untold.\n",
      "\n",
      "Masala's warmth, a fiery embrace,\n",
      "Sambar's tang, a tangy, spicy grace.\n",
      "Coconut chutney, cool and creamy bliss,\n",
      "A perfect foil to dosa's golden kiss.\n",
      "\n",
      "From street vendors' stalls to homes so grand,\n",
      "You bring joy and comfort throughout the land.\n",
      "A staple in our hearts, a culinary art,\n",
      "Dosa, my love, my very own dessert.\n",
      "\n",
      "Whether plain or filled, a culinary feat,\n",
      "You satisfy my cravings, both small and sweet.\n",
      "A breakfast feast, a lunch or dinner's dream,\n",
      "You're always there to quench my hunger's gleam.\n",
      "\n",
      "So here's to dosa, my culinary muse,\n",
      "May your crispy goodness forever infuse.\n",
      "In every bite, a taste of heaven's delight,\n",
      "Dosa, my love, my morning's shining light.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(google_api_key=\"AIzaSyB_ueuMKTa9CKHMHBa2pZt6c4t6v1W5rJ4\", model=\"gemini-pro\")\n",
    "response = llm.invoke(\"Write a poem on my love for dosa\")\n",
    "content = response.content\n",
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d81962-f13d-4574-af58-3007103aabc4",
   "metadata": {},
   "source": [
    "#### Connect with database and ask some basic questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98c709b9-5802-4da2-b205-c2c0ea21be3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import SQLDatabase\n",
    "from langchain_experimental.sql import SQLDatabaseChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da03797c-0f3b-4429-a8e6-2a2a64bd9431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE discounts (\n",
      "\tdiscount_id INTEGER NOT NULL AUTO_INCREMENT, \n",
      "\tt_shirt_id INTEGER NOT NULL, \n",
      "\tpct_discount DECIMAL(5, 2), \n",
      "\tPRIMARY KEY (discount_id), \n",
      "\tCONSTRAINT discounts_ibfk_1 FOREIGN KEY(t_shirt_id) REFERENCES t_shirts (t_shirt_id), \n",
      "\tCONSTRAINT discounts_chk_1 CHECK ((`pct_discount` between 0 and 100))\n",
      ")ENGINE=InnoDB COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4\n",
      "\n",
      "/*\n",
      "3 rows from discounts table:\n",
      "discount_id\tt_shirt_id\tpct_discount\n",
      "1\t1\t10.00\n",
      "2\t2\t15.00\n",
      "3\t3\t20.00\n",
      "*/\n",
      "\n",
      "\n",
      "CREATE TABLE t_shirts (\n",
      "\tt_shirt_id INTEGER NOT NULL AUTO_INCREMENT, \n",
      "\tbrand ENUM('Van Huesen','Levi','Nike','Adidas') NOT NULL, \n",
      "\tcolor ENUM('Red','Blue','Black','White') NOT NULL, \n",
      "\tsize ENUM('XS','S','M','L','XL') NOT NULL, \n",
      "\tprice INTEGER, \n",
      "\tstock_quantity INTEGER NOT NULL, \n",
      "\tPRIMARY KEY (t_shirt_id), \n",
      "\tCONSTRAINT t_shirts_chk_1 CHECK ((`price` between 10 and 50))\n",
      ")ENGINE=InnoDB COLLATE utf8mb4_0900_ai_ci DEFAULT CHARSET=utf8mb4\n",
      "\n",
      "/*\n",
      "3 rows from t_shirts table:\n",
      "t_shirt_id\tbrand\tcolor\tsize\tprice\tstock_quantity\n",
      "1\tAdidas\tRed\tS\t45\t62\n",
      "2\tLevi\tBlack\tXL\t48\t24\n",
      "3\tAdidas\tBlue\tS\t30\t44\n",
      "*/\n"
     ]
    }
   ],
   "source": [
    "db_user = \"root\"\n",
    "db_password = \"root\"\n",
    "db_host = \"localhost\"\n",
    "db_name = \"atliq_tshirts\"\n",
    "\n",
    "db = SQLDatabase.from_uri(f\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\",sample_rows_in_table_info=3)\n",
    "\n",
    "print(db.table_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdc96ad4-79fb-4fa0-bdbb-4d6d8801f6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s.kumar\\AppData\\Local\\Temp\\ipykernel_28848\\2107059417.py:19: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  result = db_chain.run(query)\n",
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT sum(stock_quantity) FROM t_shirts WHERE brand = 'Levi' AND color = 'White'\n",
      "SQLQuery:\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Generated SQL Query:\n",
      "SELECT SUM(`stock_quantity`) \n",
      "FROM `t_shirts` \n",
      "WHERE `brand` = 'Levi' \n",
      "  AND `color` = 'White';\n",
      "Query Result:\n",
      "(Decimal('189'),)\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = create_engine(f\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\")\n",
    "\n",
    "try: \n",
    "   # Run a query in natural language\n",
    "   # query = \"How much is the price of the inventory for all small size t-shirts?\"\n",
    "    # query = \"How many t-shirts do we have left for nike in extra small size and black color?\"\n",
    "\n",
    "    db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True, return_sql=True, use_query_checker=True)\n",
    "\n",
    "    # query = \"If we have to sell all the Levi’s T-shirts today with discounts applied. How much revenue our store will generate (post discounts)?\"\n",
    "    # Can write plan sql query as well\n",
    "    # query = \"Select SUM(price*stock_quantity) FROM t_shirts WHERE size='s'\" \n",
    "    # query = \"How many white color Levi's t shirts we have available?\"\n",
    "    query = \"SELECT sum(stock_quantity) FROM t_shirts WHERE brand = 'Levi' AND color = 'White'\"\n",
    "     \n",
    "    result = db_chain.run(query)\n",
    "\n",
    "    # Clean the SQL query by removing markdown and extra characters\n",
    "    sql_query = result.strip().replace(\"```sql\", \"\").replace(\"```\", \"\").strip()\n",
    "\n",
    "    print(\"Generated SQL Query:\")\n",
    "    print(sql_query)\n",
    "\n",
    "    # Manually run the cleaned SQL query using the SQLAlchemy engine\n",
    "    if sql_query:\n",
    "        with engine.connect() as connection:\n",
    "            # Use SQLAlchemy's text() function to ensure the query is executable\n",
    "            query = text(sql_query)\n",
    "            result = connection.execute(query)\n",
    "            rows = result.fetchall()\n",
    "\n",
    "            # Print the query results\n",
    "            print(\"Query Result:\")\n",
    "            if rows:\n",
    "                for row in rows:\n",
    "                    print(row)\n",
    "            else:\n",
    "                print(\"No results found.\")\n",
    "    else:\n",
    "        print(\"No SQL query generated.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21494b1a-0e3f-4a04-bdd7-94359b0f4186",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Query: How much is the price of the inventory for all small size t-shirts?\n",
      "How much is the price of the inventory for all small size t-shirts?\n",
      "SQLQuery:\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Generated SQL Query:\n",
      "SELECT SUM(`price` * `stock_quantity`) AS `total_price`\n",
      "FROM `t_shirts`\n",
      "WHERE `size` = 'S';\n",
      "(Decimal('17842'),)\n",
      "Stored Results: [(Decimal('17842'),)]\n"
     ]
    }
   ],
   "source": [
    "# This section to store each query result in a varibale for embedding\n",
    "\n",
    "# Create a SQLAlchemy engine\n",
    "engine = create_engine(f\"mysql+pymysql://{db_user}:{db_password}@{db_host}/{db_name}\")\n",
    "qns=[]\n",
    "\n",
    "# Function to generate and clean SQL query using the LLM\n",
    "def generate_sql_query(llm, db, query_text):\n",
    "    try:\n",
    "        # Initialize the SQLDatabaseChain with the LLM\n",
    "        db_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True, return_sql=True, use_query_checker=True)\n",
    "        # Run the LLM-generated SQL query\n",
    "        result = db_chain.run(query_text)\n",
    "        # Clean the generated SQL query by removing markdown syntax\n",
    "        cleaned_query = result.strip().replace(\"```sql\", \"\").replace(\"```\", \"\").strip()\n",
    "        return cleaned_query\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating SQL query: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to execute the cleaned SQL query using SQLAlchemy engine\n",
    "def execute_sql_query(engine, sql_query):\n",
    "    try:\n",
    "        if sql_query:\n",
    "            with engine.connect() as connection:\n",
    "                query = text(sql_query)\n",
    "                result = connection.execute(query)\n",
    "                rows = result.fetchall()\n",
    "                return rows\n",
    "        else:\n",
    "            print(\"No SQL query to execute.\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error executing SQL query: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to print and store query results\n",
    "def store_query_results(rows):\n",
    "    result_list = []\n",
    "    if rows:\n",
    "        for row in rows:\n",
    "            print(row)\n",
    "            result_list.append(row)  # Store each row in the result_list\n",
    "    else:\n",
    "        print(\"No results found.\")\n",
    "    return result_list  # Return the list of results\n",
    "\n",
    "# Example query text\n",
    "query_text = \"How much is the price of the inventory for all small size t-shirts?\"\n",
    "\n",
    "try: \n",
    "    print(f\"\\nProcessing Query: {query_text}\")\n",
    "    # Generate SQL query using LLM\n",
    "    sql_query = generate_sql_query(llm, db, query_text)\n",
    "    print(f\"Generated SQL Query:\\n{sql_query}\")\n",
    "    \n",
    "    # Execute the SQL query\n",
    "    rows = execute_sql_query(engine, sql_query)\n",
    "    \n",
    "    # Store the query results in a variable\n",
    "    stored_results = store_query_results(rows)\n",
    "    qns.append(stored_results[0])\n",
    "    print(f\"Stored Results: {stored_results}\")  # You can now use this variable for embedding or other purposes\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4dbef79-97ff-4b32-b724-b01b8b9faf51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17842.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qns1 = float(qns[0][0])\n",
    "qns1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc925be7-b59c-4179-9d81-91da8decf0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Query: How many t-shirts do we have left for nike in extra small size and red color?\n",
      "How many t-shirts do we have left for nike in extra small size and red color?\n",
      "SQLQuery:\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Generated SQL Query:\n",
      "SELECT \n",
      "    `stock_quantity`\n",
      "FROM \n",
      "    `t_shirts`\n",
      "WHERE \n",
      "    `brand` = 'Nike' AND `size` = 'XS' AND `color` = 'Red';\n",
      "(86,)\n",
      "Stored Results: [(86,)]\n"
     ]
    }
   ],
   "source": [
    "# This section to store each query result in a varibale for embedding\n",
    "\n",
    "# Example query text\n",
    "query_text = \"How many t-shirts do we have left for nike in extra small size and red color?\"\n",
    "\n",
    "try: \n",
    "    print(f\"\\nProcessing Query: {query_text}\")\n",
    "    # Generate SQL query using LLM\n",
    "    sql_query = generate_sql_query(llm, db, query_text)\n",
    "    print(f\"Generated SQL Query:\\n{sql_query}\")\n",
    "    \n",
    "    # Execute the SQL query\n",
    "    rows = execute_sql_query(engine, sql_query)\n",
    "    \n",
    "    # Store the query results in a variable\n",
    "    stored_results = store_query_results(rows)\n",
    "    qns.append(stored_results[0])\n",
    "    print(f\"Stored Results: {stored_results}\")  # You can now use this variable for embedding or other purposes\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03f30a26-ba56-423c-86f4-79a6eb3820d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qns2 = float(qns[1][0])\n",
    "qns2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e0c58d88-3b2d-45ef-bd89-f1bf3b869ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Query: If we have to sell all the Levi’s T-shirts today with discounts applied. How much revenue our store will generate (post discounts)?\n",
      "If we have to sell all the Levi’s T-shirts today with discounts applied. How much revenue our store will generate (post discounts)?\n",
      "SQLQuery:\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Generated SQL Query:\n",
      "SELECT \n",
      "    SUM(\n",
      "        CASE\n",
      "            WHEN d.`pct_discount` IS NOT NULL\n",
      "            THEN (\n",
      "                t.`price` * (\n",
      "                    1 - (\n",
      "                        d.`pct_discount` / 100\n",
      "                    )\n",
      "                )\n",
      "            )\n",
      "            ELSE t.`price`\n",
      "        END\n",
      "    )\n",
      "FROM\n",
      "    `t_shirts` AS t\n",
      "LEFT JOIN\n",
      "    `discounts` AS d\n",
      "ON\n",
      "    t.`t_shirt_id` = d.`t_shirt_id`\n",
      "WHERE \n",
      "    t.`brand` = 'Levi'\n",
      "    AND d.`pct_discount` IS NOT NULL\n",
      "LIMIT 5;\n",
      "(Decimal('76.500000'),)\n",
      "Stored Results: [(Decimal('76.500000'),)]\n"
     ]
    }
   ],
   "source": [
    "# This section to store each query result in a varibale for embedding\n",
    "\n",
    "# Example query text\n",
    "query_text = \"If we have to sell all the Levi’s T-shirts today with discounts applied. How much revenue our store will generate (post discounts)?\"\n",
    "\n",
    "try: \n",
    "    print(f\"\\nProcessing Query: {query_text}\")\n",
    "    # Generate SQL query using LLM\n",
    "    sql_query = generate_sql_query(llm, db, query_text)\n",
    "    print(f\"Generated SQL Query:\\n{sql_query}\")\n",
    "    \n",
    "    # Execute the SQL query\n",
    "    rows = execute_sql_query(engine, sql_query)\n",
    "    \n",
    "    # Store the query results in a variable\n",
    "    stored_results = store_query_results(rows)\n",
    "    qns.append(stored_results[0])\n",
    "    print(f\"Stored Results: {stored_results}\")  # You can now use this variable for embedding or other purposes\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca5a1803-8e42-49a2-9da4-47e29aec5aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Query: select sum(a.total_amount * ((100-COALESCE(discounts.pct_discount,0))/100)) as total_revenue from\n",
      "(select sum(price*stock_quantity) as total_amount, t_shirt_id from t_shirts where brand = 'Levi'\n",
      "group by t_shirt_id) a left join discounts on a.t_shirt_id = discounts.t_shirt_id\n",
      "\n",
      "select sum(a.total_amount * ((100-COALESCE(discounts.pct_discount,0))/100)) as total_revenue from\n",
      "(select sum(price*stock_quantity) as total_amount, t_shirt_id from t_shirts where brand = 'Levi'\n",
      "group by t_shirt_id) a left join discounts on a.t_shirt_id = discounts.t_shirt_id\n",
      "\n",
      "SQLQuery:\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Generated SQL Query:\n",
      "select sum(a.total_amount * ((100-COALESCE(discounts.pct_discount,0))/100)) as total_revenue from\n",
      "(select sum(price*stock_quantity) as total_amount, t_shirt_id from t_shirts where brand = 'Levi'\n",
      "group by t_shirt_id) a left join discounts on a.t_shirt_id = discounts.t_shirt_id\n",
      "(Decimal('25033.150000'),)\n",
      "Stored Results: [(Decimal('25033.150000'),)]\n"
     ]
    }
   ],
   "source": [
    "# The above query result is not correctly generated by LLM so need to write manually and keep the result for few shot training\n",
    "\n",
    "# Example query text\n",
    "query_text = \"\"\"select sum(a.total_amount * ((100-COALESCE(discounts.pct_discount,0))/100)) as total_revenue from\n",
    "(select sum(price*stock_quantity) as total_amount, t_shirt_id from t_shirts where brand = 'Levi'\n",
    "group by t_shirt_id) a left join discounts on a.t_shirt_id = discounts.t_shirt_id\n",
    "\"\"\"\n",
    "\n",
    "try: \n",
    "    print(f\"\\nProcessing Query: {query_text}\")\n",
    "    # Generate SQL query using LLM\n",
    "    sql_query = generate_sql_query(llm, db, query_text)\n",
    "    print(f\"Generated SQL Query:\\n{sql_query}\")\n",
    "    \n",
    "    # Execute the SQL query\n",
    "    rows = execute_sql_query(engine, sql_query)\n",
    "    \n",
    "    # Store the query results in a variable\n",
    "    stored_results = store_query_results(rows)\n",
    "    qns.append(stored_results[0])\n",
    "    print(f\"Stored Results: {stored_results}\")  # You can now use this variable for embedding or other purposes\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f706636d-ef17-44b6-b4fb-8d282cb02444",
   "metadata": {},
   "source": [
    "Now this is not much interesting because what is the point of giving it the ready made query? Well, we will use this same query later on for few shot learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aba67ab1-0c19-42cd-9952-c8b7b15e70f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25033.15"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qns3 = float(qns[3][0])\n",
    "qns3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87227925-28ef-46c8-af4f-9190725f9f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Query: SELECT SUM(price * stock_quantity) FROM t_shirts WHERE brand = 'Levi'\n",
      "SELECT SUM(price * stock_quantity) FROM t_shirts WHERE brand = 'Levi'\n",
      "SQLQuery:\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Generated SQL Query:\n",
      "SELECT SUM(`price` * `stock_quantity`) FROM `t_shirts` WHERE `brand` = 'Levi'\n",
      "(Decimal('26323'),)\n",
      "Stored Results: [(Decimal('26323'),)]\n"
     ]
    }
   ],
   "source": [
    "# Example query text\n",
    "query_text =\"SELECT SUM(price * stock_quantity) FROM t_shirts WHERE brand = 'Levi'\"\n",
    "\n",
    "try: \n",
    "    print(f\"\\nProcessing Query: {query_text}\")\n",
    "    # Generate SQL query using LLM\n",
    "    sql_query = generate_sql_query(llm, db, query_text)\n",
    "    print(f\"Generated SQL Query:\\n{sql_query}\")\n",
    "    \n",
    "    # Execute the SQL query\n",
    "    rows = execute_sql_query(engine, sql_query)\n",
    "    \n",
    "    # Store the query results in a variable\n",
    "    stored_results = store_query_results(rows)\n",
    "    qns.append(stored_results[0])\n",
    "    print(f\"Stored Results: {stored_results}\")  # You can now use this variable for embedding or other purposes\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87f3981a-7a96-43ba-9743-bb09e51c8392",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Decimal('17842'),),\n",
       " (86,),\n",
       " (Decimal('76.500000'),),\n",
       " (Decimal('25033.150000'),),\n",
       " (Decimal('26323'),)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0357b18-1444-4980-a8c8-6958b2accd4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26323.0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qns4 = float(qns[4][0])\n",
    "qns4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c61923bb-f5ab-4fb2-91af-6062d0c8e9ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Query: How many red Levi's t shirts we have available?\n",
      "How many red Levi's t shirts we have available?\n",
      "SQLQuery:\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Generated SQL Query:\n",
      "SELECT COUNT(*) AS `num_red_levis`\n",
      "FROM t_shirts\n",
      "WHERE `brand` = 'Levi' AND `color` = 'Red';\n",
      "(4,)\n",
      "Stored Results: [(4,)]\n"
     ]
    }
   ],
   "source": [
    "query_text =\"How many red Levi's t shirts we have available?\"\n",
    "\n",
    "try: \n",
    "    print(f\"\\nProcessing Query: {query_text}\")\n",
    "    # Generate SQL query using LLM\n",
    "    sql_query = generate_sql_query(llm, db, query_text)\n",
    "    print(f\"Generated SQL Query:\\n{sql_query}\")\n",
    "    \n",
    "    # Execute the SQL query\n",
    "    rows = execute_sql_query(engine, sql_query)\n",
    "    \n",
    "    # Store the query results in a variable\n",
    "    stored_results = store_query_results(rows)\n",
    "    qns.append(stored_results[0])\n",
    "    print(f\"Stored Results: {stored_results}\")  # You can now use this variable for embedding or other purposes\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe11f6d-816d-477c-ab81-67e91ecc8acd",
   "metadata": {},
   "source": [
    "Once again above is the wrong answer. We need to use SUM(stock_quantity). Let's run the query explicitly. We will use the result of this query later on in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02d34def-0cc7-4de5-a95c-e6cfce094912",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Query: SELECT sum(stock_quantity) FROM t_shirts WHERE brand = 'Levi' AND color = 'White'\n",
      "SELECT sum(stock_quantity) FROM t_shirts WHERE brand = 'Levi' AND color = 'White'\n",
      "SQLQuery:\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Generated SQL Query:\n",
      "SELECT SUM(`stock_quantity`) \n",
      "FROM t_shirts \n",
      "WHERE `brand` = 'Levi' \n",
      "  AND `color` = 'White';\n",
      "(Decimal('189'),)\n",
      "Stored Results: [(Decimal('189'),)]\n"
     ]
    }
   ],
   "source": [
    "query_text =\"SELECT sum(stock_quantity) FROM t_shirts WHERE brand = 'Levi' AND color = 'White'\"\n",
    "\n",
    "try: \n",
    "    print(f\"\\nProcessing Query: {query_text}\")\n",
    "    # Generate SQL query using LLM\n",
    "    sql_query = generate_sql_query(llm, db, query_text)\n",
    "    print(f\"Generated SQL Query:\\n{sql_query}\")\n",
    "    \n",
    "    # Execute the SQL query\n",
    "    rows = execute_sql_query(engine, sql_query)\n",
    "    \n",
    "    # Store the query results in a variable\n",
    "    stored_results = store_query_results(rows)\n",
    "    qns.append(stored_results[0])\n",
    "    print(f\"Stored Results: {stored_results}\")  # You can now use this variable for embedding or other purposes\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "838fcd86-6824-47c6-bc69-d1e2c6cdb966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Decimal('17842'),),\n",
       " (86,),\n",
       " (Decimal('76.500000'),),\n",
       " (Decimal('25033.150000'),),\n",
       " (Decimal('26323'),),\n",
       " (4,),\n",
       " (Decimal('189'),)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5f257af6-0861-4542-8d3a-c4790aa265df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "189.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qns5 = float(qns[6][0])\n",
    "qns5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bd2576-7749-4459-92e9-47d4615ed1d1",
   "metadata": {},
   "source": [
    "#### Few shot learning\n",
    "Few Shot Learning: When LLM doesn't provide the correct result due to wrong SQL generation in that case we need to prepare raw sql query for each question and give it to LLM after embedding it in the Chroma db\n",
    "\n",
    "We will use a few shot learning to fix issues we have seen so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5c23af54-37c6-4f96-8204-c90ffa4f8ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "few_shots = [\n",
    "    {'Question': \"How much is the total price of the inventory for all S-size t-shirts?\",\n",
    "     'SQLQuery':\"SELECT SUM(price*stock_quantity) FROM t_shirts WHERE size = 'S'\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer': qns1},\n",
    "    {'Question' : \"How many t-shirts do we have left for Nike in XS size and red color?\",\n",
    "     'SQLQuery' : \"SELECT sum(stock_quantity) FROM t_shirts WHERE brand = 'Nike' AND color = 'Red' AND size = 'XS'\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer' : qns2},\n",
    "    {'Question': \"If we have to sell all the Levi’s T-shirts today with discounts applied. How much revenue  our store will generate (post discounts)?\" ,\n",
    "     'SQLQuery' : \"\"\"SELECT sum(a.total_amount * ((100-COALESCE(discounts.pct_discount,0))/100)) as total_revenue from\n",
    "(select sum(price*stock_quantity) as total_amount, t_shirt_id from t_shirts where brand = 'Levi'\n",
    "group by t_shirt_id) a left join discounts on a.t_shirt_id = discounts.t_shirt_id\n",
    " \"\"\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer': qns3} ,\n",
    "     {'Question' : \"If we have to sell all the Levi’s T-shirts today. How much revenue our store will generate without discount?\" ,\n",
    "      'SQLQuery': \"SELECT SUM(price * stock_quantity) FROM t_shirts WHERE brand = 'Levi'\",\n",
    "      'SQLResult': \"Result of the SQL query\",\n",
    "      'Answer' : qns4},\n",
    "    {'Question': \"How many white color Levi's shirt I have?\",\n",
    "     'SQLQuery' : \"SELECT sum(stock_quantity) FROM t_shirts WHERE brand = 'Levi' AND color = 'White'\",\n",
    "     'SQLResult': \"Result of the SQL query\",\n",
    "     'Answer' : qns5\n",
    "     }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef3019f-e570-42a1-b680-d9b5e62b2181",
   "metadata": {},
   "source": [
    "### Creating Semantic Similarity Based Example Selector\r\n",
    "\r\n",
    "1. Create embeddings for the `few_shots`.\r\n",
    "2. Store the embeddings in **Chroma DB**.\r\n",
    "3. Retrieve the top most semantically close example from the vector store.\r\n",
    "ore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "60899c10-f8b7-4626-b810-5bdb1609ef18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-huggingface\n",
      "  Downloading langchain_huggingface-0.1.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-huggingface) (0.23.4)\n",
      "Collecting langchain-core<0.4,>=0.3.0 (from langchain-huggingface)\n",
      "  Downloading langchain_core-0.3.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-huggingface) (3.0.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-huggingface) (0.19.1)\n",
      "Requirement already satisfied: transformers>=4.39.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-huggingface) (4.42.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.33)\n",
      "Collecting langsmith<0.2.0,>=0.1.117 (from langchain-core<0.4,>=0.3.0->langchain-huggingface)\n",
      "  Downloading langsmith-0.1.120-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting pydantic<3.0.0,>=2.5.2 (from langchain-core<0.4,>=0.3.0->langchain-huggingface)\n",
      "  Downloading pydantic-2.9.1-py3-none-any.whl.metadata (146 kB)\n",
      "     ---------------------------------------- 0.0/147.0 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 10.2/147.0 kB ? eta -:--:--\n",
      "     ------- ----------------------------- 30.7/147.0 kB 435.7 kB/s eta 0:00:01\n",
      "     ------- ----------------------------- 30.7/147.0 kB 435.7 kB/s eta 0:00:01\n",
      "     --------------- --------------------- 61.4/147.0 kB 365.7 kB/s eta 0:00:01\n",
      "     --------------------------- -------- 112.6/147.0 kB 504.4 kB/s eta 0:00:01\n",
      "     ------------------------------ ----- 122.9/147.0 kB 450.6 kB/s eta 0:00:01\n",
      "     ------------------------------------ 147.0/147.0 kB 516.0 kB/s eta 0:00:00\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.4,>=0.3.0->langchain-huggingface) (8.5.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.11.4)\n",
      "Requirement already satisfied: Pillow in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (10.2.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (2023.10.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3.0->langchain-huggingface) (2.1)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain-huggingface) (0.27.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain-huggingface) (3.10.5)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-huggingface)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.3 (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3.0->langchain-huggingface)\n",
      "  Downloading pydantic_core-2.23.3-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2024.2.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.3)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.23.0->langchain-huggingface) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (2.2.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain-huggingface) (4.2.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain-huggingface) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.117->langchain-core<0.4,>=0.3.0->langchain-huggingface) (0.14.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2021.13.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\s.kumar\\appdata\\local\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
      "Downloading langchain_huggingface-0.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading langchain_core-0.3.0-py3-none-any.whl (405 kB)\n",
      "   ---------------------------------------- 0.0/405.1 kB ? eta -:--:--\n",
      "   --------- ------------------------------ 92.2/405.1 kB 2.6 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 153.6/405.1 kB 3.1 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 153.6/405.1 kB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 307.2/405.1 kB 1.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 337.9/405.1 kB 1.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 368.6/405.1 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 405.1/405.1 kB 1.4 MB/s eta 0:00:00\n",
      "Downloading langsmith-0.1.120-py3-none-any.whl (289 kB)\n",
      "   ---------------------------------------- 0.0/289.8 kB ? eta -:--:--\n",
      "   --------------------- ------------------ 153.6/289.8 kB 4.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 153.6/289.8 kB 4.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 256.0/289.8 kB 1.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 289.8/289.8 kB 1.8 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.9.1-py3-none-any.whl (434 kB)\n",
      "   ---------------------------------------- 0.0/434.4 kB ? eta -:--:--\n",
      "   -------------- ------------------------- 153.6/434.4 kB 9.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 153.6/434.4 kB 9.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 174.1/434.4 kB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 337.9/434.4 kB 2.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 337.9/434.4 kB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 389.1/434.4 kB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 434.4/434.4 kB 1.5 MB/s eta 0:00:00\n",
      "Downloading pydantic_core-2.23.3-cp311-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 0.2/1.9 MB 9.0 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 0.2/1.9 MB 9.0 MB/s eta 0:00:01\n",
      "   ---- ----------------------------------- 0.2/1.9 MB 1.5 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 0.3/1.9 MB 2.1 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 0.3/1.9 MB 2.1 MB/s eta 0:00:01\n",
      "   --------- ------------------------------ 0.5/1.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.5/1.9 MB 1.9 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.5/1.9 MB 1.9 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 0.7/1.9 MB 1.6 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.7/1.9 MB 1.7 MB/s eta 0:00:01\n",
      "   -------------- ------------------------- 0.7/1.9 MB 1.7 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.9/1.9 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.9/1.9 MB 1.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.9/1.9 MB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.1/1.9 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.1/1.9 MB 1.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 1.1/1.9 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.2/1.9 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.2/1.9 MB 1.5 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.3/1.9 MB 1.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.4/1.9 MB 1.5 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.4/1.9 MB 1.5 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 1.5/1.9 MB 1.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.6/1.9 MB 1.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.6/1.9 MB 1.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 1.7/1.9 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/1.9 MB 1.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 1.8/1.9 MB 1.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 1.4 MB/s eta 0:00:00\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: pydantic-core, annotated-types, pydantic, langsmith, langchain-core, langchain-huggingface\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.12\n",
      "    Uninstalling pydantic-1.10.12:\n",
      "      Successfully uninstalled pydantic-1.10.12\n",
      "  Attempting uninstall: langsmith\n",
      "    Found existing installation: langsmith 0.1.81\n",
      "    Uninstalling langsmith-0.1.81:\n",
      "      Successfully uninstalled langsmith-0.1.81\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.2.38\n",
      "    Uninstalling langchain-core-0.2.38:\n",
      "      Successfully uninstalled langchain-core-0.2.38\n",
      "Successfully installed annotated-types-0.7.0 langchain-core-0.3.0 langchain-huggingface-0.1.0 langsmith-0.1.120 pydantic-2.9.1 pydantic-core-2.23.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "anaconda-cloud-auth 0.1.4 requires pydantic<2.0, but you have pydantic 2.9.1 which is incompatible.\n",
      "langchain 0.2.16 requires langchain-core<0.3.0,>=0.2.38, but you have langchain-core 0.3.0 which is incompatible.\n",
      "langchain-community 0.2.16 requires langchain-core<0.3.0,>=0.2.38, but you have langchain-core 0.3.0 which is incompatible.\n",
      "langchain-experimental 0.0.65 requires langchain-core<0.3.0,>=0.2.38, but you have langchain-core 0.3.0 which is incompatible.\n",
      "langchain-google-genai 1.0.10 requires langchain-core<0.3,>=0.2.33, but you have langchain-core 0.3.0 which is incompatible.\n",
      "langchain-openai 0.1.23 requires langchain-core<0.3.0,>=0.2.35, but you have langchain-core 0.3.0 which is incompatible.\n",
      "langchain-text-splitters 0.2.1 requires langchain-core<0.3.0,>=0.2.0, but you have langchain-core 0.3.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2e4f0c1-0781-4def-b920-5844b2080458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import SemanticSimilarityExampleSelector\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Ensure all values are converted to strings before joining\n",
    "to_vectorize = [\" \".join(str(value) for value in example.values()) for example in few_shots]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6e4c324e-aa10-4bfc-88a9-fff2ad6fccdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"How much is the total price of the inventory for all S-size t-shirts? SELECT SUM(price*stock_quantity) FROM t_shirts WHERE size = 'S' Result of the SQL query 17842.0\",\n",
       " \"How many t-shirts do we have left for Nike in XS size and red color? SELECT sum(stock_quantity) FROM t_shirts WHERE brand = 'Nike' AND color = 'Red' AND size = 'XS' Result of the SQL query 86.0\",\n",
       " \"If we have to sell all the Levi’s T-shirts today with discounts applied. How much revenue  our store will generate (post discounts)? SELECT sum(a.total_amount * ((100-COALESCE(discounts.pct_discount,0))/100)) as total_revenue from\\n(select sum(price*stock_quantity) as total_amount, t_shirt_id from t_shirts where brand = 'Levi'\\ngroup by t_shirt_id) a left join discounts on a.t_shirt_id = discounts.t_shirt_id\\n  Result of the SQL query 25033.15\",\n",
       " \"If we have to sell all the Levi’s T-shirts today. How much revenue our store will generate without discount? SELECT SUM(price * stock_quantity) FROM t_shirts WHERE brand = 'Levi' Result of the SQL query 26323.0\",\n",
       " \"How many white color Levi's shirt I have? SELECT sum(stock_quantity) FROM t_shirts WHERE brand = 'Levi' AND color = 'White' Result of the SQL query 189.0\"]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7fff990a-ac70-4a76-83bb-67e0690b4c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorstore = Chroma.from_texts(to_vectorize, embeddings, metadatas=few_shots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a69509fb-d73b-48cb-ae0c-aa6e307eb1d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Answer': 86.0,\n",
       "  'Question': 'How many t-shirts do we have left for Nike in XS size and red color?',\n",
       "  'SQLQuery': \"SELECT sum(stock_quantity) FROM t_shirts WHERE brand = 'Nike' AND color = 'Red' AND size = 'XS'\",\n",
       "  'SQLResult': 'Result of the SQL query'},\n",
       " {'Answer': 26323.0,\n",
       "  'Question': 'If we have to sell all the Levi’s T-shirts today. How much revenue our store will generate without discount?',\n",
       "  'SQLQuery': \"SELECT SUM(price * stock_quantity) FROM t_shirts WHERE brand = 'Levi'\",\n",
       "  'SQLResult': 'Result of the SQL query'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_selector = SemanticSimilarityExampleSelector(\n",
    "    vectorstore=vectorstore,\n",
    "    k=2,\n",
    ")\n",
    "\n",
    "example_selector.select_examples({\"Question\": \"How many Adidas T shirts I have left in my store?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c55aee3f-9138-4cbb-925c-1748671a1658",
   "metadata": {},
   "outputs": [],
   "source": [
    "### my sql based instruction prompt\n",
    "mysql_prompt = \"\"\"You are a MySQL expert. Given an input question, first create a syntactically correct MySQL query to run, then look at the results of the query and return the answer to the input question.\n",
    "Unless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per MySQL. You can order the results to return the most informative data in the database.\n",
    "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\n",
    "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
    "Pay attention to use CURDATE() function to get the current date, if the question involves \"today\".\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: Question here\n",
    "SQLQuery: Query to run with no pre-amble\n",
    "SQLResult: Result of the SQLQuery\n",
    "Answer: Final answer here\n",
    "\n",
    "No pre-amble.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cb981d87-0041-40a4-8f7c-da3600b18629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.sql_database.prompt import PROMPT_SUFFIX, _mysql_prompt\n",
    "from langchain.prompts import FewShotPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6a25a8b6-40f8-45a4-b911-0b2716a47d98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a MySQL expert. Given an input question, first create a syntactically correct MySQL query to run, then look at the results of the query and return the answer to the input question.\n",
      "Unless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per MySQL. You can order the results to return the most informative data in the database.\n",
      "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\n",
      "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "Pay attention to use CURDATE() function to get the current date, if the question involves \"today\".\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: Question here\n",
      "SQLQuery: SQL Query to run\n",
      "SQLResult: Result of the SQLQuery\n",
      "Answer: Final answer here\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(_mysql_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "055fd91b-9d59-4097-934c-50fa33a66ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only use the following tables:\n",
      "{table_info}\n",
      "\n",
      "Question: {input}\n"
     ]
    }
   ],
   "source": [
    "print(PROMPT_SUFFIX)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d5aa8a-8e6d-479a-9194-25c89ef04840",
   "metadata": {},
   "source": [
    "### Setting up PromptTemplete using input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "342ab5e4-825d-4cba-91ae-4e9623c4e035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"Question\", \"SQLQuery\", \"SQLResult\",\"Answer\",],\n",
    "    template=\"\\nQuestion: {Question}\\nSQLQuery: {SQLQuery}\\nSQLResult: {SQLResult}\\nAnswer: {Answer}\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7ed7e4d6-0476-440f-80a8-7aa44c484fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a MySQL expert. Given an input question, first create a syntactically correct MySQL query to run, then look at the results of the query and return the answer to the input question.\n",
      "Unless the user specifies in the question a specific number of examples to obtain, query for at most {top_k} results using the LIMIT clause as per MySQL. You can order the results to return the most informative data in the database.\n",
      "Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap each column name in backticks (`) to denote them as delimited identifiers.\n",
      "Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do not exist. Also, pay attention to which column is in which table.\n",
      "Pay attention to use CURDATE() function to get the current date, if the question involves \"today\".\n",
      "\n",
      "Use the following format:\n",
      "\n",
      "Question: Question here\n",
      "SQLQuery: SQL Query to run\n",
      "SQLResult: Result of the SQLQuery\n",
      "Answer: Final answer here\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(_mysql_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "051a3f01-3fa1-47bd-aa18-fdfcd50c6fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# When your LLm will be confused then we are saying LLM to lookinto vector database\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,\n",
    "    example_prompt=example_prompt,\n",
    "    prefix=mysql_prompt,\n",
    "    suffix=PROMPT_SUFFIX,\n",
    "    input_variables=[\"input\", \"table_info\", \"top_k\"], #These variables are used in the prefix and suffix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2e3908f7-64da-4049-a64d-2513b54d564e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_chain = SQLDatabaseChain.from_llm(llm, db, verbose=True, prompt=few_shot_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eea02673-f1fb-43f2-919c-fe0fd657c0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\s.kumar\\AppData\\Local\\Temp\\ipykernel_28848\\2041027919.py:1: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  new_chain(\"How many white color Levi's shirt I have?\")\n",
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many white color Levi's shirt I have?\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT sum(stock_quantity) FROM t_shirts WHERE brand = 'Levi' AND color = 'White'\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(Decimal('189'),)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3m189\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': \"How many white color Levi's shirt I have?\", 'result': '189'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chain(\"How many white color Levi's shirt I have?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58068a52-a6e2-4ff1-a87c-0ce9c2cef1cc",
   "metadata": {},
   "source": [
    "Now this is working ok. Previously for this same question it was giving wrong answer because it did not use SUM clause around stock_quantity column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e973ecd2-8b8b-4bcb-96a8-d493127eb9a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How much is the price of the inventory for all small size t-shirts?\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT SUM(price * stock_quantity)\n",
      "FROM t_shirts\n",
      "WHERE size = 'S';\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(Decimal('17842'),)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3m17842\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'How much is the price of the inventory for all small size t-shirts?',\n",
       " 'result': '17842'}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chain(\"How much is the price of the inventory for all small size t-shirts?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b94d29c6-faef-4419-8540-9ac8f0a26381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If we have to sell all the Nike’s T-shirts today with discounts applied. How much revenue  our store will generate (post discounts)?\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT sum(a.total_amount * ((100-COALESCE(discounts.pct_discount,0))/100)) as total_revenue from\n",
      "(select sum(price*stock_quantity) as total_amount, t_shirt_id from t_shirts where brand = 'Nike'\n",
      "group by t_shirt_id) a left join discounts on a.t_shirt_id = discounts.t_shirt_id\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(Decimal('28907.150000'),)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3m28907.15\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'If we have to sell all the Nike’s T-shirts today with discounts applied. How much revenue  our store will generate (post discounts)?',\n",
       " 'result': '28907.15'}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chain(\"If we have to sell all the Nike’s T-shirts today with discounts applied. How much revenue  our store will generate (post discounts)?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7777c017-99e1-4bac-8f79-d749dfc097e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If we have to sell all the Van Heuson T-shirts today with discounts applied. How much revenue  our store will generate (post discounts)?\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT sum(a.total_amount * ((100-COALESCE(discounts.pct_discount,0))/100)) as total_revenue from\n",
      "(select sum(price*stock_quantity) as total_amount, t_shirt_id from t_shirts where brand = 'Van Huesen'\n",
      "group by t_shirt_id) a left join discounts on a.t_shirt_id = discounts.t_shirt_id\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(Decimal('13526.000000'),)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3m13526.00\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'If we have to sell all the Van Heuson T-shirts today with discounts applied. How much revenue  our store will generate (post discounts)?',\n",
       " 'result': '13526.00'}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chain(\"If we have to sell all the Van Heuson T-shirts today with discounts applied. How much revenue  our store will generate (post discounts)?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "05ac20ad-1aa4-4194-b8fd-002f10a944eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_chain_start callback: AttributeError(\"'NoneType' object has no attribute 'get'\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How much revenue  our store will generate by selling all Van Heuson TShirts without discount?\n",
      "SQLQuery:\u001b[32;1m\u001b[1;3mSELECT SUM(price * stock_quantity) FROM t_shirts WHERE brand = 'Van Huesen'\u001b[0m\n",
      "SQLResult: \u001b[33;1m\u001b[1;3m[(Decimal('13994'),)]\u001b[0m\n",
      "Answer:\u001b[32;1m\u001b[1;3m13994\u001b[0m\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'13994'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_chain.run('How much revenue  our store will generate by selling all Van Heuson TShirts without discount?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
